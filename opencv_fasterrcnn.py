#
# Tested on following pretrained models:
# faster_rcnn_resnet101_coco_2018_01_28
# faster_rcnn_inception_v2_coco_2018_01_28
#
#
#

import cv2
import sys
from imutils.video import FPS
import imutils
from detection_boxes import DetectBoxes

fileName = "assets/cars.mp4"

# textGraph and weight file of model
PATH_TO_TEXTGRAPH = "faster_rcnn_resnet101_coco_2018_01_28/graph.pbtxt"
PATH_TO_MODEL_WEIGHT = "faster_rcnn_resnet101_coco_2018_01_28/frozen_inference_graph.pb"

# Load network
net = cv2.dnn.readNetFromTensorflow(PATH_TO_MODEL_WEIGHT, PATH_TO_TEXTGRAPH)
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

# class names ex) person, car, truck, and etc.
PATH_TO_LABELS = "labels/mscoco_labels.names"

# load detection class, default confidence threshold is 0.5
detect = DetectBoxes(PATH_TO_LABELS, confidence_threshold=0.55)

# Set window
winName = 'Faster-RCNN'

try:
    # Read Video file
    cap = cv2.VideoCapture(fileName)
except IOError:
    print("Input video file", fileName, "doesn't exist")
    sys.exit(1)

frameCount = 0
fps = FPS().start()
while True:
    hasFrame, frame = cap.read()
    # if end of frame, program is terminated
    if not hasFrame:
        break

    # Resizing given frame to increase process time
    # frame = imutils.resize(frame, width=450)

    # Create a 4D blob from a frame.
    blob = cv2.dnn.blobFromImage(frame, swapRB=True, crop=False)

    # Set the input to the network
    net.setInput(blob)

    # Runs the forward pass
    network_output = net.forward()

    # Extract the bounding box and draw rectangles
    detect.detect_bounding_boxes(frame, network_output)

    # Efficiency information
    t, _ = net.getPerfProfile()
    label = 'Time per frame : %0.0f ms' % abs(
        t * 1000.0 / cv2.getTickFrequency())
    cv2.putText(frame, label, (0, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 0, 0))

    cv2.imshow(winName, frame)
    fps.update()
    frameCount += 1
    if cv2.waitKey(cv2.CAP_PROP_FPS) and 0xFF == ord('q'):
        break


fps.stop()
print("Video ended")
print("approximate FPS {}".format(fps.fps()))

# releases video and removes all windows generated by the program
cap.release()
cv2.destroyAllWindows()

